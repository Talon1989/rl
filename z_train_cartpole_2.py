import gym
import numpy as np
from collections import deque
from tensorflow import keras
import os


env = gym.make('CartPole-v0')
state_size = env.observation_space.shape[0]
action_size = env.action_space.n
batch_size = 2**5
n_episodes = 1000
output_directory = 'data/cartpole_2'
if not os.path.exists(output_directory):
    os.makedirs(output_directory)


class DQNAgent:

    def __init__(self, state_size, action_size):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = deque(maxlen=2000)
        self.gamma = 0.95
        self.epsilon = 1.
        self.epsilon_decay = 995/1_000
        self.epsilon_min = 1/100
        self.learning_rate = 1/1_000
        self.model = self.build_model()

    def build_model(self):
        model = keras.models.Sequential([
            keras.layers.Dense(24, input_dim=self.state_size, activation='relu'),
            keras.layers.Dense(24, activation='relu'),
            keras.layers.Dense(self.action_size, activation='linear')
        ])
        model.compile(
            loss='mse',
            optimizer=keras.optimizers.Adam(lr=self.learning_rate)
        )
        return model

    def remember(self):
        #  TODO
        pass
























































































































































































































































































































































































