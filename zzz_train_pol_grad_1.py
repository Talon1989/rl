import gym
import numpy as np
from tensorflow import keras
import tensorflow as tf


def onehot(y):
    Y = np.zeros([np.unique(y).shape[0], y.shape[0]])
    for idx, val in enumerate(y):
        Y[int(val), idx] = 1
    return Y.T


np.random.seed(1)
tf.random.set_seed(1)
n_episodes = 1_000
env = gym.make('CartPole-v1')  # env to import
env.seed(1)
env.reset()


class Reinforce:

    def __init__(self, env: gym.wrappers.time_limit.TimeLimit, weight_path: str):
        self.env = env
        self.state_size = env.observation_space.shape[0]
        self.action_size = env.action_space.n
        self.gamma = 0.99
        self.alpha = 1e-4
        self.eta = 0.01
        self.weight_path = weight_path
        self.states, self.gradients, self.rewards = [], [], []
        self.probas, self.discounted_rewards, self.total_rewards = [], [], []

    def hot_encode_action(self, action):
        action_encoded = np.zeros(self.action_size, np.float32)
        action_encoded[action] = 1
        return action_encoded

    def remember(self, s, a, a_proba, r):
        self.gradients.append(self.hot_encode_action(a) - a_proba)
        self.states.append(s)
        self.rewards.append(r)
        self.probas.append(a_proba)




































































































































































































































































































































































































































































