import numpy as np
import gym


true_result = np.array([0., 3., 3., 3., 0., 0., 0., 0., 3., 1., 0., 0., 0., 2., 1., 0.])


env_ = gym.make('FrozenLake-v0')
n_states = env_.observation_space.n
n_actions = env_.action_space.n
P = env_.P


def state_value_iteration(n_iter: int = 1000, gamma: float = 0.99):
    assert n_iter > 0
    assert 0 <= gamma <= 1
    threshold = 1e-20
    state_table = np.random.normal(loc=0, scale=0.01, size=n_states)
    for i in range(n_iter):
        state_table_copy = state_table.copy()
        for s in range(n_states):
            q_action_values = [
                sum(
                    ((r_ + gamma * state_table[s_]) * p)
                    for p, s_, r_, _ in P[s][a]
                ) for a in range(n_actions)
            ]
            state_table[s] = np.max(q_action_values)
        if np.abs(np.sum(state_table - state_table_copy)) <= threshold:
            print('stopping function at iteration n: %d' % i)
            break
    return state_table


v_star_ = state_value_iteration()


def extract_policy(v_star, gamma: float = 0.99):
    policies = []
    for s in range(n_states):
        q_action_values = [
            sum(
                ((r_ + gamma * v_star[s_]) * p)
                for p, s_, r_, _ in P[s][a]
            ) for a in range(n_actions)
        ]
        policies.append(np.argmax(q_action_values))
    return np.array(policies)


policies_ = extract_policy(v_star_)
print(
    (policies_ == true_result).all()
)





























































































































































































































































































































































































































































































